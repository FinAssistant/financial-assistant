# Story 1.4: Basic AI Conversation Interface

## Status
Approved

## Story
**As a** user,
**I want** a basic chat interface to communicate with the AI assistant,
**so that** I can start conversations and the foundation exists for future advanced AI agent features.

## Acceptance Criteria

1. Basic chat UI component with message input and conversation display
2. Simple LangGraph Orchestrator Agent that accepts messages and provides basic responses
3. AI-SDK integration for streaming conversation responses from backend to frontend
4. Conversation state management in Redux store
5. Existing authentication and navigation systems continue to work unchanged
6. New chat interface follows existing Styled Components and responsive design patterns
7. Integration with Redux store maintains current auth state behavior
8. Chat interface is covered by component tests
9. Conversation API is covered by backend tests
10. No regression in existing authentication or navigation functionality verified

## Tasks / Subtasks

- [x] **Task 1: Basic LangGraph Orchestrator Agent** (AC: 2)
  - [x] Create `backend/app/ai/langgraph_config.py` with basic LangGraph setup
  - [x] Create `backend/app/ai/orchestrator.py` with simple agent that echoes/acknowledges messages
  - [x] Add LangGraph dependencies to `backend/pyproject.toml`
  - [x] Create basic agent graph with single Orchestrator node
  - [x] Add environment configuration for LangGraph settings
  - [x] **Unit Tests**: Create `backend/tests/test_orchestrator.py` for agent message processing

- [x] **Task 2: Conversation API Endpoint** (AC: 3)
  - [x] Create `backend/app/routers/conversation.py` with `/conversation/send` endpoint
  - [x] ~~Implement AI-SDK compatible streaming response format~~ (IMPLEMENTED INCORRECTLY - Used OpenAI format)
  - [x] Integrate LangGraph Orchestrator Agent with FastAPI endpoint
  - [x] Add JWT authentication protection to conversation routes
  - [x] Update `backend/app/main.py` to include conversation router
  - [x] **API Tests**: Create `backend/tests/test_conversation_endpoints.py` for streaming and auth

- [x] **Task 2.1: Fix Backend API Format for AI SDK Compatibility** (AC: 3)
  - [x] Update `ConversationRequest` model to accept `messages: List[ClientMessage]` instead of single `message`
  - [x] Replace OpenAI streaming format with AI SDK compatible streaming format
  - [x] Update endpoint to handle AI SDK `ClientMessage[]` format properly
  - [x] Modify response to use AI SDK expected structure (not OpenAI chat completion chunks)
  - [x] **Updated Tests**: Fix `backend/tests/test_conversation_endpoints.py` to test AI SDK format

- [ ] **Task 3: Frontend API Integration with RTK Query Codegen** (AC: 4, 7)
  - [ ] **Install RTK Query Codegen**: Add `@rtk-query/codegen-openapi` to `frontend/package.json`
  - [ ] **Generate Unified API Slice**: Create `frontend/src/store/api/generated.ts` from FastAPI OpenAPI schema (includes Auth + Conversation endpoints)
  - [ ] **Replace Existing API Files**: Remove separate `authApi.ts` and update imports to use generated API
  - [ ] **Minimal Conversation State**: Create lightweight `conversationSlice.ts` for UI state only (current session ID, loading states)
  - [ ] **Update Store Config**: Update `frontend/src/store/index.ts` to use generated API and minimal conversation slice
  - [ ] **State Tests**: Create `frontend/src/store/__tests__/conversationSlice.test.ts` for minimal UI state management

- [ ] **Task 4: Chat UI Component Implementation** (AC: 1, 6)
  - [ ] **Install AI SDK**: Add `ai` package to `frontend/package.json` (`npm install ai`)
  - [ ] Create `frontend/src/components/chat/ChatInterface/index.tsx` with message display
  - [ ] Create `frontend/src/components/chat/ChatInterface/styles.ts` with responsive styling
  - [ ] Create `frontend/src/components/chat/MessageInput/index.tsx` for user input
  - [ ] Create `frontend/src/components/chat/MessageList/index.tsx` for conversation history
  - [ ] **Configure AI SDK useChat**: Set custom API endpoint to `/conversation/send` instead of default `/api/chat`
  - [ ] Implement AI-SDK useChat hook for streaming responses with endpoint configuration
  - [ ] **Component Tests**: Create `frontend/src/components/chat/__tests__/` for all chat components

- [ ] **Task 5: Integration with Navigation and Layout** (AC: 5, 6)
  - [ ] Add "Chat" navigation item to `frontend/src/components/layout/Navigation/`
  - [ ] Create `frontend/src/pages/ChatPage/index.tsx` as protected route
  - [ ] Update `frontend/src/App.tsx` with chat route and AuthGuard protection
  - [ ] Ensure chat interface follows existing responsive breakpoints
  - [ ] Test chat accessibility and keyboard navigation
  - [ ] **Integration Tests**: Create `frontend/src/tests/integration/chat-flow.test.tsx` for end-to-end chat

## Story Context

### Existing System Integration
- **Integrates with**: Authenticated user sessions (Stories 1.1-1.2), Navigation layout (Story 1.3)
- **Technology**: React + AI-SDK for frontend streaming, FastAPI + LangGraph for backend orchestration  
- **Follows pattern**: RTK Query API pattern, Styled Components UI pattern, Protected routes with AuthGuard
- **Touch points**: Redux auth state, Navigation menu, Backend conversation API

## Dev Notes

### Previous Story Insights
[Source: docs/stories/1.1-1.3.story.md completion notes]
- Authentication system fully operational with JWT tokens and protected routes
- Redux Toolkit store configured with auth state and RTK Query
- Professional UI foundation established with responsive navigation and Styled Components
- Component testing patterns established with Jest + Testing Library

### Implementation Status & Corrections Needed
**IMPORTANT**: Task 2 was completed but implemented incorrectly using OpenAI streaming format instead of AI SDK format. Task 2.1 addresses this by fixing the backend to be truly AI SDK compatible.

### Technical Stack Requirements
[Source: architecture/tech-stack.md]
- **AI Framework**: LangGraph 0.0.x for multi-agent conversation orchestration
- **Frontend AI**: AI-SDK 3.x for React AI conversation interface with streaming
- **State Management**: Redux Toolkit 1.9.x with RTK Query codegen for unified API management (minimal state usage with AI SDK)
- **Backend Framework**: FastAPI 0.104.x with async support for AI SDK compatible streaming responses
- **UI Components**: Styled Components 6.1.x following established design patterns

### File Locations
[Source: architecture/unified-project-structure.md]
- **Backend AI modules**: `backend/app/ai/`
  - `langgraph_config.py` - LangGraph configuration
  - `orchestrator.py` - Orchestrator Agent implementation
- **Backend API routes**: `backend/app/routers/conversation.py`
- **Frontend chat components**: `frontend/src/components/chat/`
  - `ChatInterface/` - Main chat container
  - `MessageInput/` - User input component  
  - `MessageList/` - Message display component
- **Frontend pages**: `frontend/src/pages/ChatPage/`
- **Redux state**: `frontend/src/store/slices/conversationSlice.ts` (minimal UI state only)
- **API integration**: `frontend/src/store/api/generated.ts` (RTK Query codegen from OpenAPI schema)

### Integration Patterns
[Source: docs/stories/1.2.story.md patterns]
- **API Pattern**: Use RTK Query codegen from FastAPI OpenAPI schema with JWT token headers
- **State Pattern**: Minimal Redux state for UI concerns, leverage AI-SDK for message management
- **Component Pattern**: Follow Styled Components with theme integration from UI foundation
- **Route Pattern**: Follow protected route pattern with AuthGuard from navigation implementation

### LangGraph Architecture Foundation
[Source: architecture/tech-stack.md, technical-assumptions.md]
- **Simple Graph**: Single Orchestrator node that processes messages and returns responses
- **Future Extensibility**: Graph structure ready for specialized agents (Onboarding, Spending, etc.)
- **Memory**: Basic in-memory conversation state, no persistence required for POC
- **Agent Capabilities**: Echo user messages with acknowledgment, prepare for future agent routing

### AI-SDK Integration Requirements
[Source: architecture/tech-stack.md]
- **Streaming Support**: Use AI-SDK useChat hook for real-time response streaming
- **API Configuration**: Configure AI SDK to use custom `/conversation/send` endpoint (not default `/api/chat`)
- **Request Format**: Backend must accept AI SDK's `messages` array format with `ClientMessage[]` structure  
- **Response Format**: Backend must provide AI SDK compatible streaming format (not OpenAI chunks)
- **Error Handling**: Graceful handling of AI service failures and network issues
- **Loading States**: Proper loading and thinking indicators during agent processing

### Coding Standards
[Source: architecture/coding-standards.md]
- **API Routes**: Use kebab-case (`/conversation/send`)
- **React Components**: Use PascalCase (`ChatInterface`, `MessageInput`, `MessageList`)
- **Python Classes**: Use PascalCase (`OrchestratorAgent`)
- **State Management**: Follow Redux patterns, never mutate state directly
- **AI Integration**: Always use AI-SDK for streaming, never direct API calls

### Testing Requirements
[Source: architecture/testing-strategy.md]
- **Backend Tests**: FastAPI async testing for conversation endpoints with AI SDK format validation
- **Frontend Tests**: Component tests for chat interface interactions with AI SDK useChat mocking
- **Integration Tests**: End-to-end chat flow from input to response via AI SDK
- **State Tests**: Redux slice testing for minimal UI state management (session ID, loading states)
- **API Tests**: Generated API slice testing with RTK Query codegen
- **AI Tests**: Mock LangGraph responses for predictable testing

#### Testing
[Source: architecture/testing-strategy.md]
**Test Standards Required:**
- **Frontend**: Jest + Testing Library with AI SDK useChat mocking patterns
- **Backend**: FastAPI TestClient with AI SDK compatible request/response validation
- **AI SDK Integration**: Mock useChat hook for component testing
- **Message Format**: Test AI SDK message structures (`ClientMessage[]` format)
- **Streaming**: Test AI SDK streaming response handling and error states
- **Endpoint Configuration**: Test AI SDK custom endpoint configuration (`/conversation/send`)

### Security and Performance
[Source: architecture/security-and-performance.md]
- **Authentication**: All conversation endpoints protected with JWT authentication
- **Input Validation**: Sanitize all user messages before processing
- **Rate Limiting**: Apply rate limiting to prevent conversation abuse
- **Streaming Performance**: Optimize for real-time message streaming
- **Error Boundaries**: Graceful handling of AI service failures

## Technical Notes

### Integration Approach
Chat component integrates into existing Layout with Navigation, uses AuthGuard protection, connects via RTK Query to FastAPI conversation endpoint that streams responses through AI-SDK.

### Existing Pattern Reference
- Follow RTK Query pattern from `frontend/src/store/api/authApi.ts`
- Use Styled Components pattern from `frontend/src/components/layout/` components
- Follow protected route pattern from existing AuthGuard implementation

### Key Constraints
- Keep Orchestrator Agent simple (basic echo/acknowledgment responses)
- Focus on UI/backend connection infrastructure, not complex AI logic
- Maintain existing authentication and navigation functionality unchanged
- Follow established component and state management patterns

## Risk and Compatibility Check

### Minimal Risk Assessment
- **Primary Risk**: AI-SDK streaming integration complexity or LangGraph setup issues
- **Mitigation**: Start with simple echo responses, add streaming incrementally
- **Rollback**: Chat feature can be disabled via navigation, no data persistence risk

### Compatibility Verification
- [x] No breaking changes to existing APIs (new endpoints only)
- [x] No database changes (in-memory conversation state)
- [x] UI changes follow existing Styled Components design patterns  
- [x] Performance impact is minimal (separate chat route and optional feature)

## Validation Checklist

### Scope Validation
- [x] Story can be completed in one focused development session (basic foundation)
- [x] Integration approach is straightforward (follows existing RTK Query + Auth patterns)
- [x] Follows existing patterns exactly (Styled Components, Redux, protected routes)
- [x] No complex design or architecture work required (basic chat interface)

### Clarity Check
- [x] Story requirements are unambiguous (basic chat with simple AI responses)
- [x] Integration points are clearly specified (Auth, Navigation, Redux, LangGraph)
- [x] Success criteria are testable (component tests, API tests, integration tests)
- [x] Rollback approach is simple (disable chat navigation item)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| [Current Date] | 1.0 | Initial story creation for basic AI conversation interface | Product Manager |

## Dev Agent Record

### Agent Model Used
- Claude Sonnet 4 (claude-sonnet-4-20250514)

### Debug Log References  
- No debug log entries required for this task

### Completion Notes List
- ✅ Task 2.1 completed: Successfully converted backend API from OpenAI format to AI SDK compatible format
- ✅ Updated ConversationRequest model to use `messages: List[ClientMessage]` array instead of single message
- ✅ Replaced OpenAI streaming response chunks with AI SDK Server-Sent Events format (start/text-start/text-delta/text-end/[DONE])
- ✅ Added required `x-vercel-ai-data-stream: v1` header for AI SDK compatibility  
- ✅ Updated both streaming (`/conversation/send`) and non-streaming (`/conversation/message`) endpoints
- ✅ All 15 backend tests pass with AI SDK format validation
- ✅ Fixed deprecated Pydantic warning by using `min_length` instead of `min_items`

### File List
- Modified: `backend/app/routers/conversation.py` - Updated to AI SDK compatible format
- Modified: `backend/tests/test_conversation_endpoints.py` - Updated tests for AI SDK format validation

## QA Results

*This section will be populated by the QA Agent after story completion*